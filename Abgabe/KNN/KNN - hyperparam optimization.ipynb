{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d585852c",
   "metadata": {},
   "source": [
    "# KNN\n",
    "This notebook shows the process of preprocessing and hyperparameter selection for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa355e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35199     False\n",
       "169917     True\n",
       "75070     False\n",
       "10146     False\n",
       "128242     True\n",
       "Name: humor, dtype: bool"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.sample(20000)\n",
    "df_target = df['humor']\n",
    "df_data = df.copy()\n",
    "df_data.drop(columns='humor')\n",
    "\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a08c5",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "The preprosessing for KNN consists of only stemming, since this approach appeared to show the best results.\n",
    "Also, the data gehts vectorized via Tf/idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be314f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#encode target to numeric\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_target = label_encoder.fit_transform(df_target)\n",
    "#df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5457550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re, string\n",
    "\n",
    "#when running for the first time you need to activate this line for once.\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#definition of stemming function\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\") # split on whitespace\n",
    "\n",
    "def tokenize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    \n",
    "    tokens = token_pattern.findall(text)\n",
    "    for item in tokens:\n",
    "        stems.append(stemmer.stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236df96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stem data with Tfidf vectorizer\n",
    "stem_vectorizer = TfidfVectorizer(tokenizer=tokenize, min_df=0.01)\n",
    "matrix = stem_vectorizer.fit_transform(df_data['text'])\n",
    "\n",
    "df_data_stemmed = pd.DataFrame(matrix.toarray(), columns=stem_vectorizer.get_feature_names())\n",
    "#display(df_data_stemmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07067ff1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Grid Search and Cross Validation\n",
    "\n",
    "In the following, different n-Values, algorithms and distance metrics are tested. Afterwards, a model with the best parameters is trained and its accuracy gets calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88747a73",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 72.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['ball_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.74806269 0.73743783 0.73243788 0.80312467 0.80281227 0.80987473\n",
      " 0.74818765 0.73700019 0.73225024        nan        nan        nan\n",
      " 0.74887517 0.73781273 0.73237524        nan        nan        nan\n",
      " 0.74806269 0.73743783 0.73243788 0.80312467 0.80281227 0.80987473]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='cosine', n_neighbors=25)\n",
      "params= {'algorithm': 'auto', 'metric': 'cosine', 'n_neighbors': 25} acc: 0.81075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create train/test split\n",
    "df_data_train, df_data_test, df_target_train, df_target_test = train_test_split(\n",
    "    df_data_stemmed, df_target, test_size=0.2, random_state=42)\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': [18,22,25],\n",
    "    'algorithm': ['auto','ball_tree','kd_tree','brute'],\n",
    "    'metric': ['euclidean','cosine']\n",
    "\n",
    "}\n",
    "knn_estimator = KNeighborsClassifier()\n",
    "\n",
    "estimator = GridSearchCV(knn_estimator,grid_params,cv=3)\n",
    "estimator.fit(df_data_train, df_target_train)\n",
    "print(estimator.best_estimator_)\n",
    "\n",
    "final_estimator_knn = estimator.best_estimator_\n",
    "\n",
    "df_prediction = final_estimator_knn.predict(df_data_test)\n",
    "\n",
    "print(\"params= {} acc: {}\".format(estimator.best_params_, accuracy_score(df_target_test, df_prediction)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81cdc1f603c531e315611687e7017b82f1a63eb722700c5abd5d378c82d30cc5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
