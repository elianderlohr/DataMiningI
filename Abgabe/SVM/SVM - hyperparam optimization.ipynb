{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d585852c",
   "metadata": {},
   "source": [
    "# SVM\n",
    "This notebook shows the process of preprocessing and hyperparameter selection for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa355e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4969      False\n",
       "143983    False\n",
       "46974     False\n",
       "7079      False\n",
       "100492    False\n",
       "Name: humor, dtype: bool"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.sample(20000)\n",
    "df_target = df['humor']\n",
    "df_data = df.copy()\n",
    "df_data.drop(columns='humor')\n",
    "\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a08c5",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "The preprosessing for SVM consists of only stemming, since this approach appeared to show the best results.\n",
    "Also, the data gehts vectorized via Tf/idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be314f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#encode target to numeric\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_target = label_encoder.fit_transform(df_target)\n",
    "#df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5457550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re, string\n",
    "\n",
    "#when running for the first time you need to activate this line for once.\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#definition of stemming function\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\") # split on whitespace\n",
    "\n",
    "def tokenize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    \n",
    "    tokens = token_pattern.findall(text)\n",
    "    for item in tokens:\n",
    "        stems.append(stemmer.stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236df96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stem data with Tfidf vectorizer\n",
    "stem_vectorizer = TfidfVectorizer(tokenizer=tokenize, min_df=0.0001)\n",
    "matrix = stem_vectorizer.fit_transform(df_data['text'])\n",
    "\n",
    "df_data_stemmed = pd.DataFrame(matrix.toarray(), columns=stem_vectorizer.get_feature_names())\n",
    "#display(df_data_stemmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd82cc9",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Grid Search and Cross Validation\n",
    "\n",
    "In the following, different parameter values are tested using a gridsearch in combination with a cross validation to find the most fitting parameter combinations for the final model.\n",
    "Note: Due to some parameter combinations being invalid, only 700 of the initial 1400 combinations could be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd15673",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "700 fits failed out of a total of 1400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "175 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "175 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "175 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "175 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.89575   0.8963125 0.8958125 0.8958125 0.8958125 0.8958125 0.8958125\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8915625 0.892375  0.892625  0.8925    0.8925    0.8925    0.8925\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8949375 0.892     0.89225   0.8924375 0.8925    0.8925    0.8925\n",
      " 0.8900625 0.88825   0.8880625 0.888125  0.8883125 0.8883125 0.8883125\n",
      " 0.890625  0.891125  0.8908125 0.8908125 0.8908125 0.8908125 0.8908125\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.887     0.88675   0.88625   0.8863125 0.8863125 0.8863125 0.8863125\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8934375 0.885875  0.8863125 0.8863125 0.886375  0.8863125 0.8863125\n",
      " 0.8826875 0.87975   0.880625  0.8803125 0.88025   0.880125  0.8801875\n",
      " 0.871875  0.8721875 0.8720625 0.8720625 0.8720625 0.8720625 0.8720625\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8656875 0.86575   0.8658125 0.8658125 0.8658125 0.8658125 0.8658125\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8905    0.8695    0.8646875 0.8655625 0.8658125 0.8658125 0.8658125\n",
      " 0.8631875 0.860125  0.8524375 0.85575   0.85625   0.8563125 0.8561875\n",
      " 0.843375  0.8434375 0.84325   0.8431875 0.8431875 0.8431875 0.8431875\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8463125 0.844875  0.845125  0.845125  0.845125  0.845125  0.845125\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8894375 0.8654375 0.84625   0.8448125 0.845125  0.8450625 0.845125\n",
      " 0.85475   0.8478125 0.83425   0.841     0.8443125 0.8454375 0.8456875\n",
      " 0.84225   0.8388125 0.838875  0.8388125 0.8388125 0.8388125 0.8388125\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.8431875 0.8391875 0.839375  0.839125  0.839125  0.839125  0.839125\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      " 0.88875   0.8649375 0.8426875 0.8408125 0.8399375 0.8399375 0.83925\n",
      " 0.8538125 0.847125  0.829375  0.8279375 0.8405625 0.843375  0.8444375]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'dual': True, 'loss': 'hinge', 'penalty': 'l2', 'tol': 0.1}\n",
      "LinearSVC(C=1, loss='hinge', max_iter=300000, random_state=42, tol=0.1)\n",
      "0.8963125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create train/test split\n",
    "df_data_train, df_data_test, df_target_train, df_target_test = train_test_split(\n",
    "    df_data_stemmed, df_target, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = LinearSVC(random_state=42,max_iter=300000)\n",
    "\n",
    "# Specify the tunable hyper parameters\n",
    "parameters = {\n",
    "    'penalty': ['l2','l1'],\n",
    "    'loss': ['hinge','squared_hinge'],\n",
    "    'dual': [True,False],\n",
    "    'tol': [1, 1e-01, 1e-02, 1e-03, 1e-04, 1e-05, 1e-06],\n",
    "    'C': [1, 2, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Define KFold parameters\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#run grid search and train model\n",
    "estimator = GridSearchCV(svm, parameters, scoring=\"accuracy\", cv=cv)\n",
    "estimator.fit(df_data_train, df_target_train)\n",
    "\n",
    "#print results\n",
    "print(estimator.best_params_)\n",
    "print(estimator.best_estimator_)\n",
    "print(estimator.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
